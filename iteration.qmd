# Iterazione {#sec-iteration}

```{r}
#| echo: false
source("_common.R")
```

## Introduzione

In questo capitolo imparerai gli strumenti per l'iterazione, eseguendo ripetutamente la stessa azione su oggetti diversi.
L'iterazione in R tende generalmente ad apparire piuttosto diversa rispetto ad altri linguaggi di programmazione perché gran parte di essa è implicita e la otteniamo gratuitamente.
Ad esempio, se vuoi raddoppiare un vettore numerico `x` in R, puoi semplicemente scrivere `2 * x`.
Nella maggior parte degli altri linguaggi, dovresti esplicitamente raddoppiare ogni elemento di `x` utilizzando qualche tipo di ciclo for.

Questo libro ti ha già fornito un piccolo ma potente numero di strumenti che eseguono la stessa azione per molteplici "cose":

-   `facet_wrap()` e `facet_grid()` disegnano un grafico per ogni sottogruppo.
-   `group_by()` più `summarize()` calcolano statistiche riassuntive per ogni sottogruppo.
-   `unnest_wider()` e `unnest_longer()` creano nuove righe e colonne per ogni elemento di una colonna-lista.

Ora è il momento di imparare alcuni strumenti più generali, spesso chiamati strumenti di **programmazione funzionale** perché sono costruiti attorno a funzioni che prendono altre funzioni come input.
Imparare la programmazione funzionale può facilmente virare verso l'astratto, ma in questo capitolo manterremo le cose concrete concentrandoci su tre compiti comuni: modificare più colonne, leggere più file e salvare più oggetti.

### Prerequisiti

In questo capitolo ci concentreremo sugli strumenti forniti da dplyr e purrr, entrambi membri centrali del tidyverse.
Hai già visto dplyr prima, ma [purrr](http://purrr.tidyverse.org/) è nuovo.
Useremo solo un paio di funzioni purrr in questo capitolo, ma è un ottimo pacchetto da esplorare mentre migliori le tue competenze di programmazione.

```{r}
#| label: setup
#| message: false
library(tidyverse)
```

## Modificare più colonne {#sec-across}

Immagina di avere questa semplice tibble e di voler contare il numero di osservazioni e calcolare la mediana di ogni colonna.

```{r}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)
```

Potresti farlo con copia e incolla:

```{r}
df |> summarize(
  n = n(),
  a = median(a),
  b = median(b),
  c = median(c),
  d = median(d),
)
```

Questo viola la nostra regola empirica di non copiare e incollare più di due volte, e puoi immaginare che questo diventerà molto noioso se hai decine o anche centinaia di colonne.
Invece, puoi usare `across()`:

```{r}
df |> summarize(
  n = n(),
  across(a:d, median),
)
```

`across()` ha tre argomenti particolarmente importanti, che discuteremo in dettaglio nelle sezioni seguenti.
Userai i primi due ogni volta che usi `across()`: il primo argomento, `.cols`, specifica su quali colonne vuoi iterare, e il secondo argomento, `.fns`, specifica cosa fare con ogni colonna.
Puoi usare l'argomento `.names` quando hai bisogno di controllo aggiuntivo sui nomi delle colonne di output, che è particolarmente importante quando usi `across()` con `mutate()`.
Discuteremo anche due importanti variazioni, `if_any()` e `if_all()`, che funzionano con `filter()`.

### Selezionare colonne con `.cols`

Il primo argomento di `across()`, `.cols`, seleziona le colonne da trasformare.
Questo usa le stesse specifiche di `select()`, @sec-select, quindi puoi usare funzioni come `starts_with()` e `ends_with()` per selezionare colonne basate sul loro nome.

Ci sono due tecniche di selezione aggiuntive che sono particolarmente utili per `across()`: `everything()` e `where()`.
`everything()` è diretto: seleziona ogni colonna (non di raggruppamento):

```{r}
df <- tibble(
  grp = sample(2, 10, replace = TRUE),
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df |> 
  group_by(grp) |> 
  summarize(across(everything(), median))
```

Nota che le colonne di raggruppamento (`grp` qui) non sono incluse in `across()`, perché sono automaticamente preservate da `summarize()`.

`where()` ti permette di selezionare colonne basate sul loro tipo:

-   `where(is.numeric)` seleziona tutte le colonne numeriche.
-   `where(is.character)` seleziona tutte le colonne stringa.
-   `where(is.Date)` seleziona tutte le colonne data.
-   `where(is.POSIXct)` seleziona tutte le colonne data-ora.
-   `where(is.logical)` seleziona tutte le colonne logiche.

Proprio come altri selettori, puoi combinarli con l'algebra booleana.
Ad esempio, `!where(is.numeric)` seleziona tutte le colonne non numeriche, e `starts_with("a") & where(is.logical)` seleziona tutte le colonne logiche il cui nome inizia con "a".

### Chiamare una singola funzione

Il secondo argomento di `across()` definisce come ogni colonna verrà trasformata.
In casi semplici, come sopra, questa sarà una singola funzione esistente.
Questa è una caratteristica piuttosto speciale di R: stiamo passando una funzione (`median`, `mean`, `str_flatten`, ...) a un'altra funzione (`across`).
Questa è una delle caratteristiche che rende R un linguaggio di programmazione funzionale.

È importante notare che stiamo passando questa funzione a `across()`, così `across()` può chiamarla; non la stiamo chiamando noi stessi.
Questo significa che il nome della funzione non dovrebbe mai essere seguito da `()`.
Se lo dimentichi, otterrai un errore:

```{r}
#| error: true
df |> 
  group_by(grp) |> 
  summarize(across(everything(), median()))
```

Questo errore sorge perché stai chiamando la funzione senza input, ad esempio:

```{r}
#| error: true
median()
```

### Chiamare più funzioni

In casi più complessi, potresti voler fornire argomenti aggiuntivi o eseguire più trasformazioni.
Motiviamo questo problema con un esempio semplice: cosa succede se abbiamo alcuni valori mancanti nei nostri dati?
`median()` propaga quei valori mancanti, dandoci un output non ottimale:

```{r}
rnorm_na <- function(n, n_na, mean = 0, sd = 1) {
  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))
}

df_miss <- tibble(
  a = rnorm_na(5, 1),
  b = rnorm_na(5, 1),
  c = rnorm_na(5, 2),
  d = rnorm(5)
)
df_miss |> 
  summarize(
    across(a:d, median),
    n = n()
  )
```

Sarebbe bello se potessimo passare a `median()` l'argomento `na.rm = TRUE` per rimuovere questi valori mancanti.
Per farlo, invece di chiamare `median()` direttamente, dobbiamo creare una nuova funzione che chiama `median()` con gli argomenti desiderati:

```{r}
df_miss |> 
  summarize(
    across(a:d, function(x) median(x, na.rm = TRUE)),
    n = n()
  )
```

Questo è un po' verboso, quindi R viene con una comoda scorciatoia: per questo tipo di funzione usa e getta, o **anonima**[^iteration-1], puoi sostituire `function` con `\`[^iteration-2]:

[^iteration-1]: Anonima, perché non le abbiamo mai esplicitamente dato un nome con `<-`.
    Un altro termine che i programmatori usano per questo è "funzione lambda".

[^iteration-2]: Nel codice più vecchio potresti vedere una sintassi che assomiglia a `~ .x + 1`.
    Questo è un altro modo di scrivere funzioni anonime ma funziona solo all'interno delle funzioni tidyverse e usa sempre il nome della variabile `.x`.
    Ora raccomandiamo la sintassi di base, `\(x) x + 1`.

```{r}
#| results: false
df_miss |> 
  summarize(
    across(a:d, \(x) median(x, na.rm = TRUE)),
    n = n()
  )
```

In entrambi i casi, `across()` si espande effettivamente al seguente codice:

```{r}
#| eval: false
df_miss |> 
  summarize(
    a = median(a, na.rm = TRUE),
    b = median(b, na.rm = TRUE),
    c = median(c, na.rm = TRUE),
    d = median(d, na.rm = TRUE),
    n = n()
  )
```

Quando rimuoviamo i valori mancanti dalla `median()`, sarebbe bello sapere quanti valori sono stati rimossi.
Possiamo scoprirlo fornendo due funzioni a `across()`: una per calcolare la mediana e l'altra per contare i valori mancanti.
Fornisci più funzioni usando una lista nominata a `.fns`:

```{r}
df_miss |> 
  summarize(
    across(a:d, list(
      median = \(x) median(x, na.rm = TRUE),
      n_miss = \(x) sum(is.na(x))
    )),
    n = n()
  )
```

Se guardi attentamente, potresti intuire che le colonne sono nominate usando una specifica glue (@sec-glue) come `{.col}_{.fn}` dove `.col` è il nome della colonna originale e `.fn` è il nome della funzione.
Non è una coincidenza!
Come imparerai nella prossima sezione, puoi usare l'argomento `.names` per fornire la tua specifica glue.

### Nomi delle colonne

Il risultato di `across()` è nominato secondo la specifica fornita nell'argomento `.names`.
Potremmo specificare la nostra se volessimo che il nome della funzione venisse prima[^iteration-3]:

[^iteration-3]: Attualmente non puoi cambiare l'ordine delle colonne, ma potresti riordinarle dopo il fatto usando `relocate()` o simile.

```{r}
df_miss |> 
  summarize(
    across(
      a:d,
      list(
        median = \(x) median(x, na.rm = TRUE),
        n_miss = \(x) sum(is.na(x))
      ),
      .names = "{.fn}_{.col}"
    ),
    n = n(),
  )
```

L'argomento `.names` è particolarmente importante quando usi `across()` con `mutate()`.
Per impostazione predefinita, l'output di `across()` riceve gli stessi nomi degli input.
Questo significa che `across()` all'interno di `mutate()` sostituirà le colonne esistenti.
Ad esempio, qui usiamo `coalesce()` per sostituire i `NA` con `0`:

```{r}
df_miss |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0))
  )
```

Se invece volessi creare nuove colonne, puoi usare l'argomento `.names` per dare all'output nuovi nomi:

```{r}
df_miss |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0), .names = "{.col}_na_zero")
  )
```

### Filtraggio

`across()` è una grande corrispondenza per `summarize()` e `mutate()` ma è più scomodo da usare con `filter()`, perché di solito combini più condizioni con `|` o `&`.
È chiaro che `across()` può aiutare a creare più colonne logiche, ma poi cosa?
Quindi dplyr fornisce due varianti di `across()` chiamate `if_any()` e `if_all()`:

```{r}
# uguale a df_miss |> filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))
df_miss |> filter(if_any(a:d, is.na))

# uguale a df_miss |> filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))
df_miss |> filter(if_all(a:d, is.na))
```

### `across()` nelle funzioni

`across()` è particolarmente utile per programmare perché ti permette di operare su più colonne.
Ad esempio, [Jacob Scott](https://twitter.com/_wurli/status/1571836746899283969) usa questo piccolo helper che avvolge un mucchio di funzioni lubridate per espandere tutte le colonne data in colonne anno, mese e giorno:

```{r}
expand_dates <- function(df) {
  df |> 
    mutate(
      across(where(is.Date), list(year = year, month = month, day = mday))
    )
}

df_date <- tibble(
  name = c("Amy", "Bob"),
  date = ymd(c("2009-08-03", "2010-01-16"))
)

df_date |> 
  expand_dates()
```

`across()` rende anche facile fornire più colonne in un singolo argomento perché il primo argomento usa tidy-select; devi solo ricordare di abbracciare quell'argomento, come abbiamo discusso in @sec-embracing.
Ad esempio, questa funzione calcolerà le medie delle colonne numeriche per impostazione predefinita.
Ma fornendo il secondo argomento puoi scegliere di riassumere solo le colonne selezionate:

```{r}
summarize_means <- function(df, summary_vars = where(is.numeric)) {
  df |> 
    summarize(
      across({{ summary_vars }}, \(x) mean(x, na.rm = TRUE)),
      n = n(),
      .groups = "drop"
    )
}
diamonds |> 
  group_by(cut) |> 
  summarize_means()

diamonds |> 
  group_by(cut) |> 
  summarize_means(c(carat, x:z))
```

### Confronto con `pivot_longer()`

Prima di continuare, vale la pena di sottolineare una connessione interessante tra `across()` e `pivot_longer()` (@sec-pivoting).
In molti casi, esegui gli stessi calcoli prima ruotando i dati e poi eseguendo le operazioni per gruppo piuttosto che per colonna.
Ad esempio, prendi questo riassunto multi-funzione:

```{r}
df |> 
  summarize(across(a:d, list(median = median, mean = mean)))
```

Potremmo calcolare gli stessi valori ruotando in lungo e poi riassumendo:

```{r}
long <- df |> 
  pivot_longer(a:d) |> 
  group_by(name) |> 
  summarize(
    median = median(value),
    mean = mean(value)
  )
long
```

E se volessi la stessa struttura di `across()` potresti ruotare di nuovo:

```{r}
long |> 
  pivot_wider(
    names_from = name,
    values_from = c(median, mean),
    names_vary = "slowest",
    names_glue = "{name}_{.value}"
  )
```

Questa è una tecnica utile da conoscere perché a volte incontrerai un problema che attualmente non è possibile risolvere con `across()`: quando hai gruppi di colonne su cui vuoi calcolare simultaneamente.
Ad esempio, immagina che il nostro data frame contenga sia valori che pesi e vogliamo calcolare una media ponderata:

```{r}
df_paired <- tibble(
  a_val = rnorm(10),
  a_wts = runif(10),
  b_val = rnorm(10),
  b_wts = runif(10),
  c_val = rnorm(10),
  c_wts = runif(10),
  d_val = rnorm(10),
  d_wts = runif(10)
)
```

Attualmente non c'è modo di farlo con `across()`[^iteration-4], ma è relativamente semplice con `pivot_longer()`:

[^iteration-4]: Forse un giorno ci sarà, ma attualmente non vediamo come.

```{r}
df_long <- df_paired |> 
  pivot_longer(
    everything(), 
    names_to = c("group", ".value"), 
    names_sep = "_"
  )
df_long

df_long |> 
  group_by(group) |> 
  summarize(mean = weighted.mean(val, wts))
```

Se necessario, potresti riportare questo con `pivot_wider()` alla forma originale.

### Esercizi

1.  Pratica le tue competenze di `across()`:

    1.  Calcolando il numero di valori unici in ogni colonna di `palmerpenguins::penguins`.

    2.  Calcolando la media di ogni colonna in `mtcars`.

    3.  Raggruppando `diamonds` per `cut`, `clarity` e `color` poi contando il numero di osservazioni e calcolando la media di ogni colonna numerica.

2.  Cosa succede se usi una lista di funzioni in `across()`, ma non le nomini?
    Come è nominato l'output?

3.  Modifica `expand_dates()` per rimuovere automaticamente le colonne data dopo che sono state espanse.
    Hai bisogno di abbracciare qualche argomento?

4.  Spiega cosa fa ogni passaggio della pipeline in questa funzione.
    Quale caratteristica speciale di `where()` stiamo sfruttando?

    ```{r}
    #| results: false
    show_missing <- function(df, group_vars, summary_vars = everything()) {
      df |> 
        group_by(pick({{ group_vars }})) |> 
        summarize(
          across({{ summary_vars }}, \(x) sum(is.na(x))),
          .groups = "drop"
        ) |>
        select(where(\(x) any(x > 0)))
    }
    nycflights13::flights |> show_missing(c(year, month, day))
    ```

## Leggere più file

Nella sezione precedente, hai imparato come usare `dplyr::across()` per ripetere una trasformazione su più colonne.
In questa sezione, imparerai come usare `purrr::map()` per fare qualcosa a ogni file in una directory.
Iniziamo con un po' di motivazione: immagina di avere una directory piena di fogli di calcolo excel[^iteration-5] che vuoi leggere.
Potresti farlo con copia e incolla:

[^iteration-5]: Se invece avessi una directory di file csv con lo stesso formato, puoi usare la tecnica di @sec-readr-directory.

```{r}
#| eval: false
data2019 <- readxl::read_excel("data/y2019.xlsx")
data2020 <- readxl::read_excel("data/y2020.xlsx")
data2021 <- readxl::read_excel("data/y2021.xlsx")
data2022 <- readxl::read_excel("data/y2022.xlsx")
```

E poi usare `dplyr::bind_rows()` per combinarli tutti insieme:

```{r}
#| eval: false
data <- bind_rows(data2019, data2020, data2021, data2022)
```

Puoi immaginare che questo diventerà tedioso rapidamente, specialmente se avessi centinaia di file, non solo quattro.
Le sezioni seguenti ti mostrano come automatizzare questo tipo di compito.
Ci sono tre passaggi di base: usa `list.files()` per elencare tutti i file in una directory, poi usa `purrr::map()` per leggere ognuno di essi in una lista, poi usa `purrr::list_rbind()` per combinarli in un singolo data frame.
Discuteremo poi come puoi gestire situazioni di crescente eterogeneità, dove non puoi fare esattamente la stessa cosa a ogni file.

### Elencare file in una directory

Come suggerisce il nome, `list.files()` elenca i file in una directory.
Userai quasi sempre tre argomenti:

-   Il primo argomento, `path`, è la directory in cui guardare.

-   `pattern` è un'espressione regolare usata per filtrare i nomi dei file.
    Il pattern più comune è qualcosa come `[.]xlsx$` o `[.]csv$` per trovare tutti i file con un'estensione specificata.

-   `full.names` determina se il nome della directory debba essere incluso nell'output o meno.
    Quasi sempre vuoi che questo sia `TRUE`.

Per rendere concreto il nostro esempio motivazionale, questo libro contiene una cartella con 12 fogli di calcolo excel contenenti dati dal pacchetto gapminder.
Ogni file contiene i dati di un anno per 142 paesi.
Possiamo elencarli tutti con la chiamata appropriata a `list.files()`:

```{r}
paths <- list.files("data/gapminder", pattern = "[.]xlsx$", full.names = TRUE)
paths
```

### Liste

Ora che abbiamo questi 12 percorsi, potremmo chiamare `read_excel()` 12 volte per ottenere 12 data frame:

```{r}
#| eval: false
gapminder_1952 <- readxl::read_excel("data/gapminder/1952.xlsx")
gapminder_1957 <- readxl::read_excel("data/gapminder/1957.xlsx")
gapminder_1962 <- readxl::read_excel("data/gapminder/1962.xlsx")
 ...,
gapminder_2007 <- readxl::read_excel("data/gapminder/2007.xlsx")
```

Ma mettere ogni foglio nella sua propria variabile renderà difficile lavorarci tra alcuni passaggi.
Invece, sarà più facile lavorarci se li mettiamo in un singolo oggetto.
Una lista è lo strumento perfetto per questo lavoro:

```{r}
#| eval: false
files <- list(
  readxl::read_excel("data/gapminder/1952.xlsx"),
  readxl::read_excel("data/gapminder/1957.xlsx"),
  readxl::read_excel("data/gapminder/1962.xlsx"),
  ...,
  readxl::read_excel("data/gapminder/2007.xlsx")
)
```

```{r}
#| include: false
files <- map(paths, readxl::read_excel)
```

Ora che hai questi data frame in una lista, come ne estrai uno?
Puoi usare `files[[i]]` per estrarre l'i<sup>esimo</sup> elemento:

```{r}
files[[3]]
```

Torneremo su `[[` in maggior dettaglio in @sec-subset-one.

### `purrr::map()` e `list_rbind()`

Il codice per raccogliere quei data frame in una lista "a mano" è fondamentalmente altrettanto tedioso da digitare quanto il codice che legge i file uno per uno.
Fortunatamente, possiamo usare `purrr::map()` per fare un uso ancora migliore del nostro vettore `paths`.
`map()` è simile a `across()`, ma invece di fare qualcosa a ogni colonna in un data frame, fa qualcosa a ogni elemento di un vettore. `map(x, f)` è una scorciatoia per:

```{r}
#| eval: false
list(
  f(x[[1]]),
  f(x[[2]]),
  ...,
  f(x[[n]])
)
```

Quindi possiamo usare `map()` per ottenere una lista di 12 data frame:

```{r}
files <- map(paths, readxl::read_excel)
length(files)

files[[1]]
```

(Questa è un'altra struttura dati che non si visualizza particolarmente in modo compatto con `str()` quindi potresti voler caricarla in RStudio e ispezionarla con `View()`).

Ora possiamo usare `purrr::list_rbind()` per combinare quella lista di data frame in un singolo data frame:

```{r}
list_rbind(files)
```

O potremmo fare entrambi i passaggi in una volta in una pipeline:

```{r}
#| results: false
paths |> 
  map(readxl::read_excel) |> 
  list_rbind()
```

Cosa succede se vogliamo passare argomenti extra a `read_excel()`?
Usiamo la stessa tecnica che abbiamo usato con `across()`.
Ad esempio, è spesso utile dare un'occhiata alle prime righe dei dati con `n_max = 1`:

```{r}
paths |> 
  map(\(path) readxl::read_excel(path, n_max = 1)) |> 
  list_rbind()
```

Questo rende chiaro che qualcosa manca: non c'è una colonna `year` perché quel valore è registrato nel percorso, non nei singoli file.
Affronteremo questo problema successivamente.

### Dati nel percorso {#sec-data-in-the-path}

A volte il nome del file è dato esso stesso.
In questo esempio, il nome del file contiene l'anno, che non è altrimenti registrato nei singoli file.
Per ottenere quella colonna nel data frame finale, dobbiamo fare due cose:

Prima, nominiamo il vettore dei percorsi.
Il modo più facile per farlo è con la funzione `set_names()`, che può prendere una funzione.
Qui usiamo `basename()` per estrarre solo il nome del file dal percorso completo:

```{r}
paths |> set_names(basename) 
```

Quei nomi vengono automaticamente portati avanti da tutte le funzioni map, quindi la lista di data frame avrà quegli stessi nomi:

```{r}
files <- paths |> 
  set_names(basename) |> 
  map(readxl::read_excel)
```

Questo rende questa chiamata a `map()` una scorciatoia per:

```{r}
#| eval: false
files <- list(
  "1952.xlsx" = readxl::read_excel("data/gapminder/1952.xlsx"),
  "1957.xlsx" = readxl::read_excel("data/gapminder/1957.xlsx"),
  "1962.xlsx" = readxl::read_excel("data/gapminder/1962.xlsx"),
  ...,
  "2007.xlsx" = readxl::read_excel("data/gapminder/2007.xlsx")
)
```

Puoi anche usare `[[` per estrarre elementi per nome:

```{r}
files[["1962.xlsx"]]
```

Poi usiamo l'argomento `names_to` di `list_rbind()` per dirgli di salvare i nomi in una nuova colonna chiamata `year` poi usiamo `readr::parse_number()` per estrarre il numero dalla stringa.

```{r}
paths |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  mutate(year = parse_number(year))
```

In casi più complicati, potrebbero esserci altre variabili memorizzate nel nome della directory, o forse il nome del file contiene più pezzi di dati.
In quel caso, usa `set_names()` (senza argomenti) per registrare il percorso completo, e poi usa `tidyr::separate_wider_delim()` e amici per trasformarli in colonne utili.

```{r}
paths |> 
  set_names() |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  separate_wider_delim(year, delim = "/", names = c(NA, "dir", "file")) |> 
  separate_wider_delim(file, delim = ".", names = c("file", "ext"))
```

### Salva il tuo lavoro

Ora che hai fatto tutto questo duro lavoro per arrivare a un bel data frame ordinato, è un ottimo momento per salvare il tuo lavoro:

```{r}
gapminder <- paths |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  mutate(year = parse_number(year))

write_csv(gapminder, "gapminder.csv")
```

Ora quando tornerai a questo problema in futuro, potrai leggere un singolo file csv.
Per dataset grandi e più ricchi, usare parquet potrebbe essere una scelta migliore di `.csv`, come discusso in @sec-parquet.

```{r}
#| include: false
unlink("gapminder.csv")
```

Se stai lavorando in un progetto, suggeriamo di chiamare il file che fa questo tipo di lavoro di preparazione dati qualcosa come `0-cleanup.R`.
Lo `0` nel nome del file suggerisce che questo dovrebbe essere eseguito prima di tutto il resto.

Se i tuoi file di dati di input cambiano nel tempo, potresti considerare di imparare uno strumento come [targets](https://docs.ropensci.org/targets/) per impostare il tuo codice di pulizia dati per rieseguirsi automaticamente ogni volta che uno dei file di input viene modificato.

### Molte iterazioni semplici

Qui abbiamo solo caricato i dati direttamente dal disco, e siamo stati abbastanza fortunati da ottenere un dataset ordinato.
Nella maggior parte dei casi, dovrai fare qualche sistemazione aggiuntiva, e hai due opzioni di base: puoi fare un round di iterazione con una funzione complessa, o fare più round di iterazione con funzioni semplici.
Nella nostra esperienza la maggior parte delle persone raggiunge prima una iterazione complessa, ma spesso stai meglio facendo più iterazioni semplici.

Ad esempio, immagina di voler leggere un mucchio di file, filtrare i valori mancanti, ruotare, e poi combinare.
Un modo di approcciarsi al problema è scrivere una funzione che prende un file e fa tutti quei passaggi poi chiamare `map()` una volta:

```{r}
#| eval: false
process_file <- function(path) {
  df <- read_csv(path)
  
  df |> 
    filter(!is.na(id)) |> 
    mutate(id = tolower(id)) |> 
    pivot_longer(jan:dec, names_to = "month")
}

paths |> 
  map(process_file) |> 
  list_rbind()
```

In alternativa, potresti eseguire ogni passaggio di `process_file()` a ogni file:

```{r}
#| eval: false
paths |> 
  map(read_csv) |> 
  map(\(df) df |> filter(!is.na(id))) |> 
  map(\(df) df |> mutate(id = tolower(id))) |> 
  map(\(df) df |> pivot_longer(jan:dec, names_to = "month")) |> 
  list_rbind()
```

Raccomandiamo questo approccio perché ti impedisce di rimanere fissato su ottenere il primo file giusto prima di passare al resto.
Considerando tutti i dati quando fai pulizia e sistemazione, è più probabile che pensi olisticamente e finisca con un risultato di qualità superiore.

In questo particolare esempio, c'è un'altra ottimizzazione che potresti fare, legando tutti i data frame insieme prima.
Poi puoi fare affidamento sul comportamento regolare di dplyr:

```{r}
#| eval: false
paths |> 
  map(read_csv) |> 
  list_rbind() |> 
  filter(!is.na(id)) |> 
  mutate(id = tolower(id)) |> 
  pivot_longer(jan:dec, names_to = "month")
```

### Dati eterogenei

Sfortunatamente, a volte non è possibile andare da `map()` direttamente a `list_rbind()` perché i data frame sono così eterogenei che `list_rbind()` o fallisce o produce un data frame che non è molto utile.
In quel caso, è comunque utile iniziare caricando tutti i file:

```{r}
#| eval: false
files <- paths |> 
  map(readxl::read_excel) 
```

Poi una strategia molto utile è catturare la struttura dei data frame così puoi esplorarla usando le tue competenze di data science.
Un modo per farlo è con questa comoda funzione `df_types`[^iteration-6] che restituisce una tibble con una riga per ogni colonna:

[^iteration-6]: Non spiegheremo come funziona, ma se guardi la documentazione per le funzioni usate, dovresti essere in grado di capirlo.

```{r}
df_types <- function(df) {
  tibble(
    col_name = names(df), 
    col_type = map_chr(df, vctrs::vec_ptype_full),
    n_miss = map_int(df, \(x) sum(is.na(x)))
  )
}

df_types(gapminder)
```

Puoi poi applicare questa funzione a tutti i file, e magari fare qualche rotazione per rendere più facile vedere dove sono le differenze.
Ad esempio, questo rende facile verificare che i fogli di calcolo gapminder con cui abbiamo lavorato sono tutti abbastanza omogenei:

```{r}
files |> 
  map(df_types) |> 
  list_rbind(names_to = "file_name") |> 
  select(-n_miss) |> 
  pivot_wider(names_from = col_name, values_from = col_type)
```

Se i file hanno formati eterogenei, potresti aver bisogno di fare più elaborazione prima di poterli unire con successo.
Sfortunatamente, ora ti lasceremo a capirlo da solo, ma potresti voler leggere su `map_if()` e `map_at()`.
`map_if()` ti permette di modificare selettivamente elementi di una lista basati sui loro valori; `map_at()` ti permette di modificare selettivamente elementi basati sui loro nomi.

### Gestire i fallimenti

A volte la struttura dei tuoi dati potrebbe essere sufficientemente selvaggia che non riesci nemmeno a leggere tutti i file con un singolo comando.
E poi incontrerai uno degli svantaggi di `map()`: ha successo o fallisce nel complesso.
`map()` o leggerà con successo tutti i file in una directory o fallirà con un errore, leggendo zero file.
Questo è fastidioso: perché un fallimento dovrebbe impedirti di accedere a tutti gli altri successi?

Fortunatamente, purrr viene con un helper per affrontare questo problema: `possibly()`.
`possibly()` è quello che è noto come operatore di funzione: prende una funzione e restituisce una funzione con comportamento modificato.
In particolare, `possibly()` cambia una funzione dal dare errore al restituire un valore che specifichi:

```{r}
files <- paths |> 
  map(possibly(\(path) readxl::read_excel(path), NULL))

data <- files |> list_rbind()
```

Questo funziona particolarmente bene qui perché `list_rbind()`, come molte funzioni tidyverse, ignora automaticamente i `NULL`.

Ora hai tutti i dati che possono essere letti facilmente, ed è il momento di affrontare la parte difficile di capire perché alcuni file non sono riusciti a caricarsi e cosa fare al riguardo.
Inizia ottenendo i percorsi che sono falliti:

```{r}
failed <- map_vec(files, is.null)
paths[failed]
```

Poi chiama di nuovo la funzione di importazione per ogni fallimento e capisci cosa è andato storto.

## Salvare più output

Nell'ultima sezione, hai imparato su `map()`, che è utile per leggere più file in un singolo oggetto.
In questa sezione, esploreremo ora il tipo di problema opposto: come puoi prendere uno o più oggetti R e salvarlo in uno o più file?
Esploreremo questa sfida usando tre esempi:

-   Salvare più data frame in un database.
-   Salvare più data frame in più file `.csv`.
-   Salvare più grafici in più file `.png`.

### Scrivere in un database {#sec-save-database}

A volte quando lavori con molti file alla volta, non è possibile adattare tutti i tuoi dati in memoria contemporaneamente, e non puoi fare `map(files, read_csv)`.
Un approccio per affrontare questo problema è caricare i tuoi dati in un database così puoi accedere solo ai pezzi di cui hai bisogno con dbplyr.

Se sei fortunato, il pacchetto database che stai usando fornirà una funzione comoda che prende un vettore di percorsi e li carica tutti nel database.
Questo è il caso con `duckdb_read_csv()` di duckdb:

```{r}
#| eval: false
con <- DBI::dbConnect(duckdb::duckdb())
duckdb::duckdb_read_csv(con, "gapminder", paths)
```

Questo funzionerebbe bene qui, ma non abbiamo file csv, invece abbiamo fogli di calcolo excel.
Quindi dovremo farlo "a mano".
Imparare a farlo a mano ti aiuterà anche quando hai un mucchio di csv e il database con cui stai lavorando non ha una funzione che li caricherà tutti.

Dobbiamo iniziare creando una tabella che riempiremo con i dati.
Il modo più facile per farlo è creando un template, un data frame fittizio che contiene tutte le colonne che vogliamo, ma solo un campionamento dei dati.
Per i dati gapminder, possiamo fare quel template leggendo un singolo file e aggiungendoci l'anno:

```{r}
template <- readxl::read_excel(paths[[1]])
template$year <- 1952
template
```

Ora possiamo connetterci al database, e usare `DBI::dbCreateTable()` per trasformare il nostro template in una tabella del database:

```{r}
con <- DBI::dbConnect(duckdb::duckdb())
DBI::dbCreateTable(con, "gapminder", template)
```

`dbCreateTable()` non usa i dati in `template`, solo i nomi delle variabili e i tipi.
Quindi se ispezionassimo la tabella `gapminder` ora vedresti che è vuota ma ha le variabili di cui abbiamo bisogno con i tipi che ci aspettiamo:

```{r}
con |> tbl("gapminder")
```

Successivamente, abbiamo bisogno di una funzione che prende un singolo percorso file, lo legge in R, e aggiunge il risultato alla tabella `gapminder`.
Possiamo farlo combinando `read_excel()` con `DBI::dbAppendTable()`:

```{r}
append_file <- function(path) {
  df <- readxl::read_excel(path)
  df$year <- parse_number(basename(path))
  
  DBI::dbAppendTable(con, "gapminder", df)
}
```

Ora dobbiamo chiamare `append_file()` una volta per ogni elemento di `paths`.
Questo è certamente possibile con `map()`:

```{r}
#| eval: false
paths |> map(append_file)
```

Ma non ci importa dell'output di `append_file()`, quindi invece di `map()` è leggermente più carino usare `walk()`.
`walk()` fa esattamente la stessa cosa di `map()` ma butta via l'output:

```{r}
paths |> walk(append_file)
```

Ora possiamo vedere se abbiamo tutti i dati nella nostra tabella:

```{r}
con |> 
  tbl("gapminder") |> 
  count(year)
```

```{r}
#| include: false
DBI::dbDisconnect(con, shutdown = TRUE)
```

### Scrivere file csv

Lo stesso principio di base si applica se vogliamo scrivere più file csv, uno per ogni gruppo.
Immaginiamo di voler prendere i dati `ggplot2::diamonds` e salvare un file csv per ogni `clarity`.
Prima dobbiamo fare quei dataset individuali.
Ci sono molti modi in cui potresti farlo, ma c'è un modo che ci piace particolarmente: `group_nest()`.

```{r}
by_clarity <- diamonds |> 
  group_nest(clarity)

by_clarity
```

Questo ci dà una nuova tibble con otto righe e due colonne.
`clarity` è la nostra variabile di raggruppamento e `data` è una colonna-lista contenente una tibble per ogni valore unico di `clarity`:

```{r}
by_clarity$data[[1]]
```

Mentre siamo qui, creiamo una colonna che dà il nome del file di output, usando `mutate()` e `str_glue()`:

```{r}
by_clarity <- by_clarity |> 
  mutate(path = str_glue("diamonds-{clarity}.csv"))

by_clarity
```

Quindi se dovessimo salvare questi data frame a mano, potremmo scrivere qualcosa come:

```{r}
#| eval: false
write_csv(by_clarity$data[[1]], by_clarity$path[[1]])
write_csv(by_clarity$data[[2]], by_clarity$path[[2]])
write_csv(by_clarity$data[[3]], by_clarity$path[[3]])
...
write_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])
```

Questo è un po' diverso dai nostri usi precedenti di `map()` perché ci sono due argomenti che stanno cambiando, non solo uno.
Questo significa che abbiamo bisogno di una nuova funzione: `map2()`, che varia sia il primo che il secondo argomento.
E poiché di nuovo non ci importa dell'output, vogliamo `walk2()` piuttosto che `map2()`.
Questo ci dà:

```{r}
walk2(by_clarity$data, by_clarity$path, write_csv)
```

```{r}
#| include: false
unlink(by_clarity$path)
```

### Salvare grafici

Possiamo prendere lo stesso approccio di base per creare molti grafici.
Prima facciamo una funzione che disegna il grafico che vogliamo:

```{r}
#| fig-alt: |
#|   Istogramma dei carati dei diamanti dal dataset by_clarity, che va da 
#|   0 a 5 carati. La distribuzione è unimodale e asimmetrica a destra con un picco 
#|   intorno a 1 carato.

carat_histogram <- function(df) {
  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  
}

carat_histogram(by_clarity$data[[1]])
```

Ora possiamo usare `map()` per creare una lista di molti grafici[^iteration-7] e i loro eventuali percorsi file:

[^iteration-7]: Puoi stampare `by_clarity$plot` per ottenere un'animazione rudimentale --- otterrai un grafico per ogni elemento di `plots`.
    NOTA: questo non è successo per me.

```{r}
by_clarity <- by_clarity |> 
  mutate(
    plot = map(data, carat_histogram),
    path = str_glue("clarity-{clarity}.png")
  )
```

Poi usa `walk2()` con `ggsave()` per salvare ogni grafico:

```{r}
walk2(
  by_clarity$path,
  by_clarity$plot,
  \(path, plot) ggsave(path, plot, width = 6, height = 6)
)
```

Questo è una scorciatoia per:

```{r}
#| eval: false
ggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)
ggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)
ggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)
...
ggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)
```

```{r}
#| include: false
unlink(by_clarity$path)
```

```{=html}
<!-- 
### Esercizi

1.  Immagina di avere una tabella di dati degli studenti contenente (tra le altre variabili) `school_name` e `student_id`. Abbozza che codice scriveresti se volessi salvare tutte le informazioni per ogni studente in un file chiamato `{student_id}.csv` nella directory `{school}`.
-->
```

## Riassunto

In questo capitolo, hai visto come usare l'iterazione esplicita per risolvere tre problemi che sorgono frequentemente quando fai data science: manipolare più colonne, leggere più file e salvare più output.
Ma in generale, l'iterazione è un super potere: se conosci la tecnica di iterazione giusta, puoi facilmente passare dal risolvere un problema al risolvere tutti i problemi.
Una volta che hai padroneggiato le tecniche in questo capitolo, raccomandiamo vivamente di imparare di più leggendo il [capitolo Functionals](https://adv-r.hadley.nz/functionals.html) di *Advanced R* e consultando il [sito web purrr](https://purrr.tidyverse.org).

Se sai molto sull'iterazione in altri linguaggi, potresti essere sorpreso che non abbiamo discusso il ciclo `for`.
Questo perché l'orientamento di R verso l'analisi dei dati cambia come iteriamo: nella maggior parte dei casi puoi fare affidamento su un idioma esistente per fare qualcosa a ogni colonna o ogni gruppo.
E quando non puoi, spesso puoi usare uno strumento di programmazione funzionale come `map()` che fa qualcosa a ogni elemento di una lista.
Tuttavia, vedrai cicli `for` nel codice catturato in natura, quindi imparerai su di essi nel prossimo capitolo dove discuteremo alcuni importanti strumenti di base R.