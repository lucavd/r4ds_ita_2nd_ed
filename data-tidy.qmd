# Ordinare i dati {#sec-data-tidy}

```{r}
#| echo: false
source("_common.R")
```

## Introduzione

> "Le famiglie felici sono tutte uguali; ogni famiglia infelice è infelice a modo suo."\
> --- Leo Tolstoy

> "I dataset ordinati sono tutti uguali, ma ogni dataset disordinato è disordinato a modo suo."\
> --- Hadley Wickham

In questo capitolo, imparerai un modo consistente per organizzare i tuoi dati in R usando un sistema chiamato **dati ordinati**.
Portare i tuoi dati in questo formato richiede un po' di lavoro iniziale, ma quel lavoro ripaga nel lungo termine.
Una volta che hai dati ordinati e gli strumenti ordinati forniti dai pacchetti nel tidyverse, spenderai molto meno tempo a manipolare dati da una rappresentazione all'altra, permettendoti di spendere più tempo sulle domande sui dati che ti interessano.

In questo capitolo, prima imparerai la definizione di dati ordinati e la vedrai applicata a un semplice dataset di esempio.
Poi ci immergeremo nello strumento principale che userai per ordinare i dati: il pivoting.
Il pivoting ti permette di cambiare la forma dei tuoi dati senza cambiare nessuno dei valori.

### Prerequisiti

In questo capitolo, ci concentreremo su tidyr, un pacchetto che fornisce un gruppo di strumenti per aiutare a ordinare i tuoi dataset disordinati.
tidyr è un membro del tidyverse principale.

```{r}
#| label: setup
#| message: false
library(tidyverse)
```

Da questo capitolo in poi, sopprimeremo il messaggio di caricamento da `library(tidyverse)`.

## Dati ordinati {#sec-tidy-data}

Puoi rappresentare gli stessi dati sottostanti in modi multipli.
L'esempio sotto mostra gli stessi dati organizzati in tre modi diversi.
Ogni dataset mostra gli stessi valori di quattro variabili: *paese*, *anno*, *popolazione*, e numero di *casi* documentati di TB (tubercolosi), ma ogni dataset organizza i valori in modo diverso.

```{r}
table1

table2

table3
```

Queste sono tutte rappresentazioni degli stessi dati sottostanti, ma non sono ugualmente facili da usare.
Una di esse, `table1`, sarà molto più facile da lavorare dentro il tidyverse perché è **ordinata**.

Ci sono tre regole interconnesse che rendono un dataset ordinato:

1.  Ogni variabile è una colonna; ogni colonna è una variabile.
2.  Ogni osservazione è una riga; ogni riga è un'osservazione.
3.  Ogni valore è una cella; ogni cella è un singolo valore.

@fig-tidy-structure shows the rules visually.

```{r}
#| label: fig-tidy-structure
#| echo: false
#| fig-cap: | 
#|   Le seguenti tre regole rendono un dataset ordinato: le variabili sono colonne,
#|   le osservazioni sono righe, e i valori sono celle.
#| fig-alt: | 
#|   Tre pannelli, ognuno che rappresenta un data frame ordinato. Il primo pannello
#|   mostra che ogni variabile è una colonna. Il secondo pannello mostra che ogni
#|   osservazione è una riga. Il terzo pannello mostra che ogni valore è
#|   una cella.
knitr::include_graphics("images/tidy-1.png", dpi = 270)
```

Perché assicurarsi che i tuoi dati siano ordinati?
Ci sono due vantaggi principali:

1.  C'è un vantaggio generale nel scegliere un modo consistente di memorizzare dati.
    Se hai una struttura dati consistente, è più facile imparare gli strumenti che lavorano con essa perché hanno un'uniformità sottostante.

2.  C'è un vantaggio specifico nel posizionare variabili in colonne perché permette alla natura vettorizzata di R di brillare.
    Come hai imparato in @sec-mutate e @sec-summarize, la maggior parte delle funzioni R integrate lavorano con vettori di valori.
    Questo rende la trasformazione di dati ordinati particolarmente naturale.

dplyr, ggplot2, e tutti gli altri pacchetti nel tidyverse sono progettati per lavorare con dati ordinati.
Ecco alcuni piccoli esempi che mostrano come potresti lavorare con `table1`.

```{r}
#| fig-width: 5
#| fig-alt: |
#|   Questa figura mostra il numero di casi nel 1999 e 2000 per 
#|   Afghanistan, Brasile, e Cina, con l'anno sull'asse x e il numero 
#|   di casi sull'asse y. Ogni punto sul grafico rappresenta il numero 
#|   di casi in un dato paese in un dato anno. I punti per ogni
#|   paese sono differenziati dagli altri per colore e forma e collegati
#|   con una linea, risultando in tre linee non parallele e non intersecanti.
#|   I numeri di casi in Cina sono i più alti sia per il 1999 che per il 2000, con
#|   valori sopra i 200.000 per entrambi gli anni. Il numero di casi in Brasile è
#|   circa 40.000 nel 1999 e circa 75.000 nel 2000. I
#|   numeri di casi in Afghanistan sono i più bassi sia per il 1999 che per il 2000, con
#|   valori che appaiono molto vicini a 0 su questa scala.
# Calcola tasso per 10.000
table1 |>
  mutate(rate = cases / population * 10000)

# Calcola casi totali per anno
table1 |> 
  group_by(year) |> 
  summarize(total_cases = sum(cases))

# Visualizza cambiamenti nel tempo
ggplot(table1, aes(x = year, y = cases)) +
  geom_line(aes(group = country), color = "grey50") +
  geom_point(aes(color = country, shape = country)) +
  scale_x_continuous(breaks = c(1999, 2000)) # interruzioni asse x a 1999 e 2000
```

### Esercizi

1.  Per ognuna delle tabelle di esempio, descrivi cosa rappresenta ogni osservazione e ogni colonna.

2.  Abbozza il processo che useresti per calcolare il `rate` per `table2` e `table3`.
    Dovrai eseguire quattro operazioni:

    a.  Estrarre il numero di casi TB per paese per anno.
    b.  Estrarre la popolazione corrispondente per paese per anno.
    c.  Dividere i casi per la popolazione, e moltiplicare per 10000.
    d.  Memorizzare nel posto appropriato.

    Non hai ancora imparato tutte le funzioni di cui avresti bisogno per eseguire effettivamente queste operazioni, ma dovresti essere ancora in grado di pensare alle trasformazioni di cui avresti bisogno.

## Allungare i dati {#sec-pivoting}

I principi dei dati ordinati potrebbero sembrare così ovvi che ti chiedi se incontrerai mai un dataset che non è ordinato.
Sfortunatamente, tuttavia, la maggior parte dei dati reali non è ordinata.
Ci sono due ragioni principali:

1.  I dati sono spesso organizzati per facilitare qualche obiettivo diverso dall'analisi.
    Per esempio, è comune che i dati siano strutturati per rendere facile l'inserimento dei dati, non l'analisi.

2.  La maggior parte delle persone non è familiare con i principi dei dati ordinati, ed è difficile derivarli da soli a meno che tu non spenda molto tempo lavorando con i dati.

Questo significa che la maggior parte delle analisi reali richiederà almeno un po' di ordinamento.
Inizirai capendo quali sono le variabili e osservazioni sottostanti.
A volte questo è facile; altre volte dovrai consultare le persone che hanno originariamente generato i dati.
Successivamente, farai il **pivot** dei tuoi dati in una forma ordinata, con variabili nelle colonne e osservazioni nelle righe.

tidyr fornisce due funzioni per il pivot dei dati: `pivot_longer()` e `pivot_wider()`.
Iniziamo prima con `pivot_longer()` perché è il caso più comune.
Immergiamoci in alcuni esempi.

### Dati nei nomi delle colonne {#sec-billboard}

Il dataset `billboard` registra la classifica billboard delle canzoni nell'anno 2000:

```{r}
billboard
```

In questo dataset, ogni osservazione è una canzone.
Le prime tre colonne (`artist`, `track` e `date.entered`) sono variabili che descrivono la canzone.
Poi abbiamo 76 colonne (`wk1`-`wk76`) che descrivono la classifica della canzone in ogni settimana[^data-tidy-1].
Qui, i nomi delle colonne sono una variabile (la `week`) e i valori delle celle sono un'altra (il `rank`).

[^data-tidy-1]: La canzone sarà inclusa finché era nella top 100 a un certo punto nel 2000, ed è tracciata per fino a 72 settimane dopo che appare.

Per ordinare questi dati, useremo `pivot_longer()`:

```{r, R.options=list(pillar.print_min = 10)}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
```

Dopo i dati, ci sono tre argomenti chiave:

-   `cols` specifica quali colonne devono essere ruotate, cioè quali colonne non sono variabili. Questo argomento usa la stessa sintassi di `select()` quindi qui potremmo usare `!c(artist, track, date.entered)` o `starts_with("wk")`.
-   `names_to` nomina la variabile memorizzata nei nomi delle colonne, abbiamo nominato quella variabile `week`.
-   `values_to` nomina la variabile memorizzata nei valori delle celle, abbiamo nominato quella variabile `rank`.

Nota che nel codice `"week"` e `"rank"` sono tra virgolette perché sono nuove variabili che stiamo creando, non esistono ancora nei dati quando eseguiamo la chiamata `pivot_longer()`.

Ora rivolgiamo la nostra attenzione al data frame risultante, più lungo.
Cosa succede se una canzone è nella top 100 per meno di 76 settimane?
Take 2 Pac's "Baby Don't Cry", for example.
The above output suggests that it was only in the top 100 for 7 weeks, and all the remaining weeks are filled in with missing values.
These `NA`s don't really represent unknown observations; they were forced to exist by the structure of the dataset[^data-tidy-2], so we can ask `pivot_longer()` to get rid of them by setting `values_drop_na = TRUE`:

[^data-tidy-2]: We'll come back to this idea in @sec-missing-values.

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

The number of rows is now much lower, indicating that many rows with `NA`s were dropped.

You might also wonder what happens if a song is in the top 100 for more than 76 weeks?
We can't tell from this data, but you might guess that additional columns `wk77`, `wk78`, ...
would be added to the dataset.

This data is now tidy, but we could make future computation a bit easier by converting values of `week` from character strings to numbers using `mutate()` and `readr::parse_number()`.
`parse_number()` is a handy function that will extract the first number from a string, ignoring all other text.

```{r}
billboard_longer <- billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  ) |> 
  mutate(
    week = parse_number(week)
  )
billboard_longer
```

Now that we have all the week numbers in one variable and all the rank values in another, we're in a good position to visualize how song ranks vary over time.
The code is shown below and the result is in @fig-billboard-ranks.
We can see that very few songs stay in the top 100 for more than 20 weeks.

```{r}
#| label: fig-billboard-ranks
#| fig-cap: |
#|   A line plot showing how the rank of a song changes over time.
#| fig-alt: |
#|   A line plot with week on the x-axis and rank on the y-axis, where
#|   each line represents a song. Most songs appear to start at a high rank,
#|   rapidly accelerate to a low rank, and then decay again. There are
#|   surprisingly few tracks in the region when week is >20 and rank is
#|   >50.
billboard_longer |> 
  ggplot(aes(x = week, y = rank, group = track)) + 
  geom_line(alpha = 0.25) + 
  scale_y_reverse()
```

### Come funziona il pivoting?

Ora che hai visto come possiamo usare il pivoting per rimodellare i nostri dati, prendiamo un po' di tempo per acquisire un'intuizione su cosa fa il pivoting ai dati.
Iniziamo con un dataset molto semplice per rendere più facile vedere cosa sta succedendo.
Supponi di avere tre pazienti con `id` A, B, e C, e prendiamo due misurazioni della pressione sanguigna su ogni paziente.
Creeremo i dati con `tribble()`, una funzione pratica per costruire piccoli tibble a mano:

```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)
```

Vogliamo che il nostro nuovo dataset abbia tre variabili: `id` (esiste già), `measurement` (i nomi delle colonne), e `value` (i valori delle celle).
Per ottenere questo, dobbiamo fare il pivot di `df` più lungo:

```{r}
df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  )
```

Come funziona il rimodellamento?
È più facile da vedere se ci pensiamo colonna per colonna.
Come mostrato in @fig-pivot-variables, i valori in una colonna che era già una variabile nel dataset originale (`id`) devono essere ripetuti, una volta per ogni colonna che viene ruotata.

```{r}
#| label: fig-pivot-variables
#| echo: false
#| fig-cap: | 
#|   Le colonne che sono già variabili devono essere ripetute, una volta per
#|   ogni colonna che viene ruotata.
#| fig-alt: | 
#|   Un diagramma che mostra come `pivot_longer()` trasforma un semplice
#|   dataset, usando il colore per evidenziare come i valori nella colonna `id`
#|   ("A", "B", "C") sono ognuno ripetuti due volte nell'output perché ci sono
#|   due colonne che vengono ruotate ("bp1" e "bp2").
knitr::include_graphics("diagrams/tidy-data/variables.png", dpi = 270)
```

I nomi delle colonne diventano valori in una nuova variabile, il cui nome è definito da `names_to`, come mostrato in @fig-pivot-names.
Devono essere ripetuti una volta per ogni riga nel dataset originale.

```{r}
#| label: fig-pivot-names
#| echo: false
#| fig-cap: |
#|   The column names of pivoted columns become values in a new column. The 
#|   values need to be repeated once for each row of the original dataset.
#| fig-alt: | 
#|   A diagram showing how `pivot_longer()` transforms a simple
#|   data set, using color to highlight how column names ("bp1" and 
#|   "bp2") become the values in a new `measurement` column. They are repeated
#|   three times because there were three rows in the input.
knitr::include_graphics("diagrams/tidy-data/column-names.png", dpi = 270)
```

The cell values also become values in a new variable, with a name defined by `values_to`.
They are unwound row by row.
@fig-pivot-values illustrates the process.

```{r}
#| label: fig-pivot-values
#| echo: false
#| fig-cap: |
#|   The number of values is preserved (not repeated), but unwound
#|   row-by-row.
#| fig-alt: | 
#|   A diagram showing how `pivot_longer()` transforms data,
#|   using color to highlight how the cell values (blood pressure measurements)
#|   become the values in a new `value` column. They are unwound row-by-row,
#|   so the original rows (100,120), then (140,115), then (120,125), become 
#|   a column running from 100 to 125.
knitr::include_graphics("diagrams/tidy-data/cell-values.png", dpi = 270)
```

### Many variables in column names

A more challenging situation occurs when you have multiple pieces of information crammed into the column names, and you would like to store these in separate new variables.
For example, take the `who2` dataset, the source of `table1` and friends that you saw above:

```{r}
who2
```

This dataset, collected by the World Health Organisation, records information about tuberculosis diagnoses.
There are two columns that are already variables and are easy to interpret: `country` and `year`.
They are followed by 56 columns like `sp_m_014`, `ep_m_4554`, and `rel_m_3544`.
If you stare at these columns for long enough, you'll notice there's a pattern.
Each column name is made up of three pieces separated by `_`.
The first piece, `sp`/`rel`/`ep`, describes the method used for the diagnosis, the second piece, `m`/`f` is the `gender` (coded as a binary variable in this dataset), and the third piece, `014`/`1524`/`2534`/`3544`/`4554`/`5564`/`65` is the `age` range (`014` represents 0-14, for example).

So in this case we have six pieces of information recorded in `who2`: the country and the year (already columns); the method of diagnosis, the gender category, and the age range category (contained in the other column names); and the count of patients in that category (cell values).
To organize these six pieces of information in six separate columns, we use `pivot_longer()` with a vector of column names for `names_to` and instructors for splitting the original variable names into pieces for `names_sep` as well as a column name for `values_to`:

```{r}
who2 |> 
  pivot_longer(
    cols = !(country:year),
    names_to = c("diagnosis", "gender", "age"), 
    names_sep = "_",
    values_to = "count"
  )
```

An alternative to `names_sep` is `names_pattern`, which you can use to extract variables from more complicated naming scenarios, once you've learned about regular expressions in @sec-regular-expressions.

Conceptually, this is only a minor variation on the simpler case you've already seen.
@fig-pivot-multiple-names shows the basic idea: now, instead of the column names pivoting into a single column, they pivot into multiple columns.
You can imagine this happening in two steps (first pivoting and then separating) but under the hood it happens in a single step because that's faster.

```{r}
#| label: fig-pivot-multiple-names
#| echo: false
#| fig-cap: |
#|   Pivoting columns with multiple pieces of information in the names 
#|   means that each column name now fills in values in multiple output 
#|   columns.
#| fig-alt: |
#|   A diagram that uses color to illustrate how supplying `names_sep` 
#|   and multiple `names_to` creates multiple variables in the output.
#|   The input has variable names "x_1" and "y_2" which are split up
#|   by "_" to create name and number columns in the output. This is
#|   is similar case with a single `names_to`, but what would have been a
#|   single output variable is now separated into multiple variables.
knitr::include_graphics("diagrams/tidy-data/multiple-names.png", dpi = 270)
```

### Data and variable names in the column headers

The next step up in complexity is when the column names include a mix of variable values and variable names.
For example, take the `household` dataset:

```{r}
household
```

This dataset contains data about five families, with the names and dates of birth of up to two children.
The new challenge in this dataset is that the column names contain the names of two variables (`dob`, `name`) and the values of another (`child`, with values 1 or 2).
To solve this problem we again need to supply a vector to `names_to` but this time we use the special `".value"` sentinel; this isn't the name of a variable but a unique value that tells `pivot_longer()` to do something different.
This overrides the usual `values_to` argument to use the first component of the pivoted column name as a variable name in the output.

```{r}
household |> 
  pivot_longer(
    cols = !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```

We again use `values_drop_na = TRUE`, since the shape of the input forces the creation of explicit missing variables (e.g., for families with only one child).

@fig-pivot-names-and-values illustrates the basic idea with a simpler example.
When you use `".value"` in `names_to`, the column names in the input contribute to both values and variable names in the output.

```{r}
#| label: fig-pivot-names-and-values
#| echo: false
#| fig-cap: |
#|   Pivoting with `names_to = c(".value", "num")` splits the column names
#|   into two components: the first part determines the output column
#|   name (`x` or `y`), and the second part determines the value of the
#|   `num` column.
#| fig-alt: |
#|   A diagram that uses color to illustrate how the special ".value"
#|   sentinel works. The input has names "x_1", "x_2", "y_1", and "y_2",
#|   and we want to use the first component ("x", "y") as a variable name
#|   and the second ("1", "2") as the value for a new "num" column.
knitr::include_graphics("diagrams/tidy-data/names-and-values.png", dpi = 270)
```

## Allargare i dati

Finora abbiamo usato `pivot_longer()` per risolvere la classe comune di problemi dove i valori sono finiti nei nomi delle colonne.
Successivamente ruoteremo (AH AH) a `pivot_wider()`, che rende i dataset **più larghi** aumentando le colonne e riducendo le righe e aiuta quando un'osservazione è distribuita su più righe.
Questo sembra emergere meno comunemente in natura, ma sembra comparire molto quando si ha a che fare con dati governativi.

Inizieremo guardando `cms_patient_experience`, un dataset dai Centers of Medicare and Medicaid services che raccoglie dati sulle esperienze dei pazienti:

```{r}
cms_patient_experience
```

L'unità principale studiata è un'organizzazione, ma ogni organizzazione è distribuita su sei righe, con una riga per ogni misurazione presa nell'organizzazione del sondaggio.
Possiamo vedere l'insieme completo di valori per `measure_cd` e `measure_title` usando `distinct()`:

```{r}
cms_patient_experience |> 
  distinct(measure_cd, measure_title)
```

Nessuna di queste colonne farà nomi di variabile particolarmente ottimi: `measure_cd` non accenna al significato della variabile e `measure_title` è una lunga frase contenente spazi.
Useremo `measure_cd` come fonte per i nostri nuovi nomi di colonna per ora, ma in un'analisi reale potresti voler creare i tuoi nomi di variabile che sono sia corti che significativi.

`pivot_wider()` ha l'interfaccia opposta a `pivot_longer()`: invece di scegliere nuovi nomi di colonna, dobbiamo fornire le colonne esistenti che definiscono i valori (`values_from`) e il nome della colonna (`names_from`):

```{r}
cms_patient_experience |> 
  pivot_wider(
    names_from = measure_cd,
    values_from = prf_rate
  )
```

L'output non sembra del tutto giusto; sembra che abbiamo ancora righe multiple per ogni organizzazione.
Questo perché, dobbiamo anche dire a `pivot_wider()` quale colonna o colonne hanno valori che identificano univocamente ogni riga; in questo caso sono le variabili che iniziano con `"org"`:

```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```

Questo ci dà l'output che stiamo cercando.

### Come funziona `pivot_wider()`?

Per capire come funziona `pivot_wider()`, iniziamo di nuovo con un dataset molto semplice.
This time we have two patients with `id`s A and B, we have three blood pressure measurements on patient A and two on patient B:

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)
```

We'll take the values from the `value` column and the names from the `measurement` column:

```{r}
df |> 
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```

To begin the process `pivot_wider()` needs to first figure out what will go in the rows and columns.
The new column names will be the unique values of `measurement`.

```{r}
df |> 
  distinct(measurement) |> 
  pull()
```

By default, the rows in the output are determined by all the variables that aren't going into the new names or values.
These are called the `id_cols`.
Here there is only one column, but in general there can be any number.

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct()
```

`pivot_wider()` then combines these results to generate an empty data frame:

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)
```

It then fills in all the missing values using the data in the input.
In this case, not every cell in the output has a corresponding value in the input as there's no third blood pressure measurement for patient B, so that cell remains missing.
We'll come back to this idea that `pivot_wider()` can "make" missing values in @sec-missing-values.

You might also wonder what happens if there are multiple rows in the input that correspond to one cell in the output.
The example below has two rows that correspond to `id` "A" and `measurement` "bp1":

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "A",        "bp1",    102,
  "A",        "bp2",    120,
  "B",        "bp1",    140, 
  "B",        "bp2",    115
)
```

If we attempt to pivot this we get an output that contains list-columns, which you'll learn more about in @sec-rectangling:

```{r}
df |>
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```

Since you don't know how to work with this sort of data yet, you'll want to follow the hint in the warning to figure out where the problem is:

```{r}
df |> 
  group_by(id, measurement) |> 
  summarize(n = n(), .groups = "drop") |> 
  filter(n > 1)
```

It's then up to you to figure out what's gone wrong with your data and either repair the underlying damage or use your grouping and summarizing skills to ensure that each combination of row and column values only has a single row.

## Riassunto

In questo capitolo hai imparato sui dati ordinati: dati che hanno variabili nelle colonne e osservazioni nelle righe.
I dati ordinati rendono il lavoro nel tidyverse più facile, perché è una struttura consistente capita dalla maggior parte delle funzioni, la sfida principale è trasformare i dati da qualsiasi struttura tu li riceva in un formato ordinato.
A tal fine, hai imparato su `pivot_longer()` e `pivot_wider()` che ti permettono di ordinare molti dataset disordinati.
Gli esempi che abbiamo presentato qui sono una selezione di quelli da `vignette("pivot", package = "tidyr")`, quindi se incontri un problema che questo capitolo non ti aiuta a risolvere, quella vignette è un buon posto da provare successivamente.

Un'altra sfida è che, per un dato dataset, può essere impossibile etichettare la versione più lunga o più larga come quella "ordinata".
Questo è in parte un riflesso della nostra definizione di dati ordinati, dove abbiamo detto che i dati ordinati hanno una variabile in ogni colonna, ma non abbiamo effettivamente definito cosa sia una variabile (ed è sorprendentemente difficile farlo).
È totalmente giusto essere pragmatici e dire che una variabile è qualsiasi cosa renda la tua analisi più facile.
Quindi se sei bloccato nel capire come fare qualche calcolo, considera di cambiare l'organizzazione dei tuoi dati; non aver paura di disordinare, trasformare, e riordinare secondo necessità!

Se ti è piaciuto questo capitolo e vuoi imparare di più sulla teoria sottostante, puoi imparare di più sulla storia e i fondamenti teorici nel paper [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) pubblicato nel Journal of Statistical Software.

Ora che stai scrivendo una quantità sostanziale di codice R, è ora di imparare di più sull'organizzare il tuo codice in file e directory.
Nel prossimo capitolo, imparerai tutto sui vantaggi di script e progetti, e alcuni dei molti strumenti che forniscono per rendere la tua vita più facile.